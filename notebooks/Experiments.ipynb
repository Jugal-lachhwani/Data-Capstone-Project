{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e7c2752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import dagshub\n",
    "import mlflow.sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,classification_report,confusion_matrix\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import logging\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c01759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7976fcdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Every great gangster movie has under-currents ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I just saw this film last night, and I have to...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film is mildly entertaining if one neglec...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quentin Tarantino's partner in crime Roger Ava...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I sat through this on TV hoping because of the...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  Every great gangster movie has under-currents ...  positive\n",
       "1  I just saw this film last night, and I have to...  positive\n",
       "2  This film is mildly entertaining if one neglec...  negative\n",
       "3  Quentin Tarantino's partner in crime Roger Ava...  negative\n",
       "4  I sat through this on TV hoping because of the...  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a2f65bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    \"\"\"Lemmatize the text.\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    \"\"\"Remove stop words from the text.\"\"\"\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    text = [word for word in str(text).split() if word not in stop_words]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_numbers(text):\n",
    "    \"\"\"Remove numbers from the text.\"\"\"\n",
    "    text = ''.join([char for char in text if not char.isdigit()])\n",
    "    return text\n",
    "\n",
    "def lower_case(text):\n",
    "    \"\"\"Convert text to lower case.\"\"\"\n",
    "    text = text.split()\n",
    "    text = [word.lower() for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_punctuations(text):\n",
    "    \"\"\"Remove punctuations from the text.\"\"\"\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    text = text.replace('ÿõ', \"\")\n",
    "    text = re.sub('\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def removing_urls(text):\n",
    "    \"\"\"Remove URLs from the text.\"\"\"\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "def normalize_text(df):\n",
    "    \"\"\"Normalize the text data.\"\"\"\n",
    "    try:\n",
    "        df['review'] = df['review'].apply(lower_case)\n",
    "        df['review'] = df['review'].apply(remove_stop_words)\n",
    "        df['review'] = df['review'].apply(removing_numbers)\n",
    "        df['review'] = df['review'].apply(removing_punctuations)\n",
    "        df['review'] = df['review'].apply(removing_urls)\n",
    "        df['review'] = df['review'].apply(lemmatization)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error during text normalization: {e}')\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bfacf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4abd0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>every great gangster movie under current human...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saw film last night say loved every minute tak...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>film mildly entertaining one neglect acknowled...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quentin tarantino s partner crime roger avary ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sat tv hoping name would worth time but dear g...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  every great gangster movie under current human...  positive\n",
       "1  saw film last night say loved every minute tak...  positive\n",
       "2  film mildly entertaining one neglect acknowled...  negative\n",
       "3  quentin tarantino s partner crime roger avary ...  negative\n",
       "4  sat tv hoping name would worth time but dear g...  negative"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = normalize_text(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e59b82a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>every great gangster movie under current human...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saw film last night say loved every minute tak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>film mildly entertaining one neglect acknowled...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quentin tarantino s partner crime roger avary ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sat tv hoping name would worth time but dear g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  every great gangster movie under current human...          1\n",
       "1  saw film last night say loved every minute tak...          1\n",
       "2  film mildly entertaining one neglect acknowled...          0\n",
       "3  quentin tarantino s partner crime roger avary ...          0\n",
       "4  sat tv hoping name would worth time but dear g...          0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'] = df['sentiment'].map({'positive':1, 'negative':0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27f76526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9d2adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=100)\n",
    "X = vectorizer.fit_transform(df['review'])\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22659016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "008bd717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as Jugal-lachhwani\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as Jugal-lachhwani\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"Jugal-lachhwani/Data-Capstone-Project\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"Jugal-lachhwani/Data-Capstone-Project\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository Jugal-lachhwani/Data-Capstone-Project initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository Jugal-lachhwani/Data-Capstone-Project initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"https://dagshub.com/Jugal-lachhwani/Data-Capstone-Project.mlflow\")\n",
    "dagshub.init(repo_owner='Jugal-lachhwani', repo_name='Data-Capstone-Project', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbd83fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/6e52a587d59c4f7987160b71fe653f07', creation_time=1760846762471, experiment_id='0', last_update_time=1760846762471, lifecycle_stage='active', name='Logistic Regression Baseline', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Logistic Regression Baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e44f92a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mlflow==2.16.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cb480cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow version: 2.16.2\n"
     ]
    }
   ],
   "source": [
    "# Check MLflow version and disable model registry features for DagHub compatibility\n",
    "import mlflow\n",
    "print(f\"MLflow version: {mlflow.__version__}\")\n",
    "\n",
    "# Disable the logged model feature that DagHub doesn't support\n",
    "os.environ[\"MLFLOW_ENABLE_LOGGED_MODEL_CREATION\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "720a68d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-19 12:26:20,671 - INFO - trying to connect to mlflow...\n",
      "2025-10-19 12:26:22,001 - INFO - Logging preprocessing parameters in mlflow...\n",
      "2025-10-19 12:26:22,001 - INFO - Logging preprocessing parameters in mlflow...\n",
      "2025-10-19 12:26:23,172 - INFO - Intializing logistic regression model...\n",
      "2025-10-19 12:26:23,172 - INFO - Intializing logistic regression model...\n",
      "2025-10-19 12:26:25,269 - INFO - Training...\n",
      "2025-10-19 12:26:25,269 - INFO - Training...\n",
      "2025-10-19 12:26:25,326 - INFO - Make predictions...\n",
      "2025-10-19 12:26:25,328 - INFO - Calculating evaluation metrics...\n",
      "2025-10-19 12:26:25,326 - INFO - Make predictions...\n",
      "2025-10-19 12:26:25,328 - INFO - Calculating evaluation metrics...\n",
      "2025-10-19 12:26:25,349 - INFO - Logging evaluation metrics...\n",
      "2025-10-19 12:26:25,349 - INFO - Logging evaluation metrics...\n",
      "2025-10-19 12:26:26,942 - INFO - Accuracy: 0.64\n",
      "2025-10-19 12:26:26,942 - INFO - Precision: 0.6610169491525424\n",
      "2025-10-19 12:26:26,944 - INFO - Recall: 0.609375\n",
      "2025-10-19 12:26:26,945 - INFO - F1 Score: 0.6341463414634146\n",
      "2025-10-19 12:26:26,942 - INFO - Accuracy: 0.64\n",
      "2025-10-19 12:26:26,942 - INFO - Precision: 0.6610169491525424\n",
      "2025-10-19 12:26:26,944 - INFO - Recall: 0.609375\n",
      "2025-10-19 12:26:26,945 - INFO - F1 Score: 0.6341463414634146\n",
      "2025-10-19 12:26:26,969 - INFO - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.67      0.65        61\n",
      "           1       0.66      0.61      0.63        64\n",
      "\n",
      "    accuracy                           0.64       125\n",
      "   macro avg       0.64      0.64      0.64       125\n",
      "weighted avg       0.64      0.64      0.64       125\n",
      "\n",
      "2025-10-19 12:26:26,971 - INFO - preparing confusion_metrics\n",
      "2025-10-19 12:26:26,974 - INFO - Confusion Matrix:\n",
      "[[41 20]\n",
      " [25 39]]\n",
      "2025-10-19 12:26:26,976 - INFO - Saving and logging the model...\n",
      "2025-10-19 12:26:26,969 - INFO - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.67      0.65        61\n",
      "           1       0.66      0.61      0.63        64\n",
      "\n",
      "    accuracy                           0.64       125\n",
      "   macro avg       0.64      0.64      0.64       125\n",
      "weighted avg       0.64      0.64      0.64       125\n",
      "\n",
      "2025-10-19 12:26:26,971 - INFO - preparing confusion_metrics\n",
      "2025-10-19 12:26:26,974 - INFO - Confusion Matrix:\n",
      "[[41 20]\n",
      " [25 39]]\n",
      "2025-10-19 12:26:26,976 - INFO - Saving and logging the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/19 12:26:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-19 12:26:37,750 - INFO - Model training and logging completed in 15.75 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/19 12:26:38 INFO mlflow.tracking._tracking_service.client: üèÉ View run mercurial-hen-120 at: https://dagshub.com/Jugal-lachhwani/Data-Capstone-Project.mlflow/#/experiments/0/runs/d064ac937ebd4aee8c2b5fddbfaed9d2.\n",
      "2025/10/19 12:26:38 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/Jugal-lachhwani/Data-Capstone-Project.mlflow/#/experiments/0.\n",
      "2025/10/19 12:26:38 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/Jugal-lachhwani/Data-Capstone-Project.mlflow/#/experiments/0.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Reset logging configuration for notebook\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ],\n",
    "    force=True  # Force reconfiguration\n",
    ")\n",
    "\n",
    "params = {'random_state':42,'max_iter':1000}\n",
    "\n",
    "logging.info(\"trying to connect to mlflow...\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        logging.info(\"Logging preprocessing parameters in mlflow...\")\n",
    "        mlflow.log_param(\"vectorizer\",\"Bag of words\")\n",
    "        mlflow.log_param(\"num_features\",100)\n",
    "        mlflow.log_param(\"test_size\",0.25)\n",
    "        \n",
    "        logging.info(\"Intializing logistic regression model...\")\n",
    "        model = LogisticRegression(max_iter=1000,random_state=42)\n",
    "        mlflow.log_param(\"model\",\"LogisticRegression\")\n",
    "        mlflow.log_param(\"max_iter_logistic\",1000)\n",
    "        mlflow.log_param(\"random_state\",42)\n",
    "        mlflow.log_dict(params,'params.json')\n",
    "        \n",
    "        logging.info(\"Training...\")\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        logging.info(\"Make predictions...\")\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        logging.info(\"Calculating evaluation metrics...\")\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        logging.info(\"Logging evaluation metrics...\")\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        \n",
    "        logging.info(f\"Accuracy: {accuracy}\")\n",
    "        logging.info(f\"Precision: {precision}\")\n",
    "        logging.info(f\"Recall: {recall}\")\n",
    "        logging.info(f\"F1 Score: {f1}\")\n",
    "        logging.info(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "        \n",
    "        logging.info(\"preparing confusion_metrics\")\n",
    "        logging.info(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n",
    "        \n",
    "        logging.info(\"Saving and logging the model...\")\n",
    "        # Save model without model registry (DagHub compatible)\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Model training and logging completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\", exc_info=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fe0a0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10-19-2025-18-28-15'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime('%m-%d-%Y-%H-%M-%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1f3758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
